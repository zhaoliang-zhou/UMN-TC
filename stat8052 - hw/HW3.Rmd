---
title: "HW-3"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(mvtnorm)
library(nCDunnett)
library(MASS)
library(ggplot2)
library(dplyr)
```



# 1. E7.2

## (a)
```{r}
power.anova.test(groups = 3, n=NULL, between.var = var(c(10,11,11)), within.var = 4, sig.level = 0.05, power = 0.9)
```

For this problem, we have: 
$$g=3 \\ \mu_i = (10,11,11) \\ \sigma = 4 \\ significance=0.05 \\
power = 0.9$$

Using the power.anova.test, we find that if we want power to be 0.9, we need 77 observations for each group. Or, the total sample size should be 231. 




## Additioanlly (b)

For this problem, we want to compare treatment groups to the control group. Let $g=3$ be the number of groups. simultaneous erroe rate is 5%, and the mean difference between the new groups and the control group is 1. Since we want to use a balance design $n_i = n_g$, By the Dunnet's method, the CI for $\mu_i - \mu_{control}$ is :
$$(\mu_i - \mu_{control}) \pm d_\epsilon (g-1, df_E) \sqrt{MS_E (1/n_i + 1/n_j)} $$

with allocacation: 
$$n_g = n \sqrt{g-1} \\ n_i =n$$


Thus, the sampel size for each group must satisfy the inequality: 
$$ n \geq 4*2*d_\epsilon(g-1, df_E)^2$$



```{r}
n0  <- 5
while (1 <= qNCDun(0.95, 3*n0-3, rho = 0.5, delta = rep(0, times = 3), two.sided =T)*sqrt(4*(1/n0 + 1/n0))){
  n0 <- n0+1
}
print(n0)

```
Thus, by usign a iterative procesdure, 46 sample for each group or total sample size 138 works for this problem. 


## 2. E7.5


## (a)
For this problem, let $\mu_i$ be the mean for each group and $i =1,2,3,4,5,6$. For this problem, we want to compare when high cost tapes average have 1 unit difference from the low cost tapes average, or equivelently:
$$(\mu_1 + \mu_3 + \mu_5 + \mu_6)/4 - (\mu_2 + \mu_4)/2 =1 $$

Or, we can consider using a contrast with coefficients $w_i = (0.25, -0.5, 0.25, -0.5, 0.25, 0.25)$. For the non-centrality parameter NCP, we can use the formula on the top of page P158, where the numerator can be denoted as $c$, and in this case we have $c=1$ since the difference is 1. Now we have: 
$$c = 1 \\ n_i = 4 \\ g=6 \\
\sigma = 0.25 \\ df_E = n-g = 24-6 = 18 \\
\epsilon = 0.01$$


```{r}
signif <- 0.01
w <- c(0.25, -0.5, 0.25, -0.5, 0.25, 0.25)
c <- 1
sigma <- 0.25
NCP <- c^2 / (sigma*sum(w^2)/4)
F_crit <- qf(1-signif, df1=1, df2 = 18)
powerE75 <- 1 - pf(F_crit, df1 = 1, df2 = 18, ncp=NCP)
powerE75
```
The power is about 0.945 when testing at the 0.01 significance level if the high cost tapes have an average 1 unit different from the low cost tapes. 

## (b)
For this problem, we are comparing brand A and brand B, thus we could use a contrast $w=(0.5, 0.5, -0.5 , -0.5, 0,0)$

The width of the confidence interval need to satisfy 
$$w \geq t_{\epsilon/2,df_E} \sqrt{MS_E \sum (w_i)^2 /n}$$
The width of CI for contrast is given in P151 and P152. using the formula, and we want our 95% CI no wider than 2
```{r}
w1 <- c(0.5, 0.5, -0.5 , -0.5, 0,0)
n_int <- 2

while(2* qt(0.975, df=6*n_int - 6)*sqrt(0.25 * sum(w1^2)/n_int) >= 2){
  n_int = n_int+1
}

print(n_int)
```



# 3. P7.2


## (a)
For this problem, we have: 
$$g = 3 \\ \mu_i = (45, 32,60) \\ \sigma=35 \\ power = 0.95 \\ \epsilon_1 = 0.01$$

To find the sampel size: 


```{r}
power.anova.test(groups = 3, n = NULL, between.var = var(c(45,32,60)), within.var = 35, sig.level = 0.01, power = 0.95)

```

Thus, we need at least 4 subjects for each group (or 12 subjects total) to have power 0.95 when testing at the significance level 0.01. 


## Additionally (b)

```{r}
g <- 3 
MSe <- 35 
c <- 5
n1 <- 2
alpha <- 0.01/2
while(1 - pf(qf(1-alpha, df1=1, df2 = n1*g-g), df1=1, df2=n1*g-g, ncp = c^2/(MSe*2/n1)) <= 0.95){
  n1 = n1 +1
}
print(n1)
```
Thus, sample size of 57 for each group (or 171 total) is needed to meet the requirement of 95% power to detect the difference of 5 units for each comparison. 




# 4. P8.5
## (a)

```{r}
pine.df <- read.table("http://www.stat.umn.edu/~gary/book/fcdae.data/pr8.5",header=TRUE)
```


```{r}
pine.df$shape <- as.factor(pine.df$shape)
pine.df$trt <- as.factor(pine.df$trt)

```




```{r}
#check assumtions

lm1 <- lm(y ~ shape + trt, data = pine.df)
par(mfrow = c(2,2))
plot(lm1)

```

From the diagnosis plot, when looking at the residual vs. fitted plot, we can see that the variance of the residuals increases as the fitted value increases which indicate there might be potential unequal variance. When looking at the Normal Q-Q plot, we see that the points deviate a little from the dotted straight line especially at two ends. Thus, transformation of the response might be necessary.  


```{r}
bc_trans <- boxcox(lm1, lambda = seq(-4,4,0.1))
  
  
```

```{r}
pos <- which.max(bc_trans$y)
bc_trans$x[pos]
```


```{r}
bc_trans$x[bc_trans$y > max(bc_trans$y) - 1/2 * qchisq(.95,1)]
```
The 95% confidence interval for $\lambda$ is $(0.04, 0.6)$. Thus, for convenience, we can pick $\lambda = 0.5$ which is the square root transformation of the response. 


```{r}
pine.df$y_sqrt <- sqrt(pine.df$y)
```


```{r}
lm2 <- lm(y_sqrt ~ trt + shape, data=pine.df)
par(mfrow = c(2,2))
plot(lm2)

```
For the diagnosis plots above, when looking at the residuals vs. fitted plot, the points seem to fall above and below the horizontal line $y=0$ equally, thus the equal variance assumtion seem to hold. Looking at the Normal Q-Q plot, the poins deviate from the dotted straight line a lot less than before, thus the normality assumtion seems to hold. 

```{r}
#ANOVA 
anova(lm2)

```

From the above ANOVA output, we can see that the treatment has an F value of 32.051 with corresponding p-value less than 0.01. Also, shape has an F value 228.964 with corresponding p-value less than 0.01. Since both p-values are statistically significant, it provides strong evidence to support treatment and shape has effects on the totla grams of resin collected (response y) and to be the main effects. 
Then, we check for the interactions:

```{r}
lm3 <- lm(y_sqrt ~ trt*shape, data=pine.df)
anova(lm3)

```
From the above ANOVA output, we can see the test statistic for treatment and shape individually still remain statistically significant with corresponding p-value less than 0.01 for each. However, the interaction effect of treatment and shape has test statistic 0.4581 and corresponding p-value 0.7154 which is larger than 0.05. Thus, there is not enough evidence to support there is an interaction effect between treatment and shape. To see this visually: 

```{r}
pine.df %>% 
  ggplot() +
  aes(x = trt, color = shape, group = shape, y = y ) +
  stat_summary(fun.y = mean, geom = "point") +
  stat_summary(fun.y = mean, geom = "line")

```
From the above plot, when plotting treatments on x-axis and mean y on y_-axis, we can see there is no interaction between different shape when treatment from 1 to 2. Also, from this plot, we can see shape 1,2,3,4 all have increasing in mean response as treatment 1 from 2, and shape 4 has the highest mean response overall.  

```{r}
pine.df %>% 
  ggplot() +
  aes(x = shape, color = trt, group = trt, y = y ) +
  stat_summary(fun.y = mean, geom = "point") +
  stat_summary(fun.y = mean, geom = "line")

```

Similarly, we can plot shape on x-axis, mean y on y-axis, and we can see as shape increases from 1 to 4, there is no interaction between treatment group 1 and 2. We can also see treatment 1 and 2 all have increasing mean response as shape moves from 1 to 4, and treatment 2 has highest mean response. 
Then, conduct comparisons by mean and treatment

```{r}
aov.mod <- aov(lm2)
TukeyHSD(aov.mod, "shape")
```
From the above output, we compared all possible pairs of shape, and all the p-values are less than 0.01 which are all statistically significant. Thus, we can conclude shape has effect on total resin collected (response y)





```{r}
TukeyHSD(aov.mod, "trt")
```
From the above output, we compared treatment 1 and 2, or Control vs. Acid group. The p-value is close to 0, and the 95% family-wise CI does not include 0. These provide strong evidence that Acid treatment has effect on total resin collected. 



## Additionally (b)
```{r}
lm4 <- lm(y_sqrt ~ trt + shape + trt:shape, data=pine.df)
aov.mod4 <- aov(lm4)
TukeyHSD(aov.mod4, "trt:shape")
```

From the above output, we can find the CI for 2:4 - 1:1 is (5.487, 7.927) or the CI for $\mu_{24} - \mu_{11}$ is (5.487, 7.927). Thus, for the other direction, the CI for  

$\mu_{11} - \mu_{24}$ is then $(-7.927,-5.487)$ 










