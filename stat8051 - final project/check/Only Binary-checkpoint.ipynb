{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from scipy.stats import uniform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_predict, cross_val_score, GroupKFold, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel, RFECV, chi2\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "from sklearn.metrics import make_scorer, mean_poisson_deviance, mean_gamma_deviance, classification_report, brier_score_loss\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector, TransformedTargetRegressor\n",
    "from sklearn.preprocessing import PowerTransformer, OneHotEncoder, StandardScaler, PolynomialFeatures, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, RidgeClassifierCV, PoissonRegressor, GammaRegressor, TweedieRegressor, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingRegressor, BaggingClassifier, StackingRegressor, HistGradientBoostingRegressor, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import LinearSVR, LinearSVC, SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "df = pd.read_csv('InsNova_train.csv')\n",
    "df = df.sample(frac=1.0)\n",
    "df.loc[:, 'pure_premium'] = df['claim_cost'] / df['exposure']\n",
    "df.loc[:, 'severity'] = df['claim_cost'] / np.fmax(df['claim_count'], 1)\n",
    "df.loc[:, 'frequency'] = df['claim_count'] / df['exposure']\n",
    "\n",
    "# Getting CV inds\n",
    "n_folds = 20\n",
    "cv = StratifiedKFold(n_folds, shuffle=True, random_state=123)\n",
    "df.loc[:, 'fold'] = 0\n",
    "for fold, (_, test_inds) in enumerate(cv.split(df, df['claim_ind'])):\n",
    "    df.loc[test_inds, 'fold'] = fold\n",
    "    \n",
    "# Feature engineering\n",
    "df['large_veh'] = np.where(df['veh_body'].isin(['MIBUS', 'MCARA', 'BUS']), 1, 0)\n",
    "df['expensive_area'] = np.where(df['area'].isin(['E','F']), 1, 0)\n",
    "df['expensive_age_risk'] = np.where(df['dr_age'].isin([1, 2]) & (df['veh_value'] > 5.0), 1, 0)\n",
    "df['expensive_veh'] = np.where(df['veh_value'] > 6.0, 1, 0)\n",
    "df['severe_veh'] = np.where(df['veh_body'].isin(['HDTOP', 'TRUCK', 'UTE']), 1, 0)\n",
    "df['young_dr'] = np.where(df['dr_age'] == 1, 1, 0)\n",
    "df['old_dr'] = np.where(df['dr_age'] > 4.0, 1, 0)\n",
    "df['new_veh'] = np.where(df['veh_age'] < 2.0, 1, 0)\n",
    "df['old_veh'] = np.where(df['veh_age'] == 4.0, 1, 0)\n",
    "df['frequent_area'] = np.where(df['area'].isin(['B','F']), 1, 0)\n",
    "df['young_dr_old_car'] = np.where((df['dr_age'] == 1) & (df['veh_age'] > 1.0), 1, 0)\n",
    "df['young_m_old_car'] = np.where((df['dr_age'] == 1) & (df['veh_age'] > 1.0) & (df['gender'] == 'M'), 1, 0)\n",
    "df['young_f_old_car'] = np.where((df['dr_age'] == 1) & (df['veh_age'] > 1.0) & (df['gender'] == 'F'), 1, 0)\n",
    "df['frequent_body'] = np.where(df['veh_body'].isin(['BUS', 'COUPE', 'HDTOP', 'MCARA', 'PANVN', 'STNWG']), 1, 0)\n",
    "df['infrequent_body'] = np.where(df['veh_body'].isin(['MIBUS', 'UTE']), 1, 0)\n",
    "df['young_m'] = np.where((df['gender'] == 'M') & (df['dr_age'] < 3.0), 1, 0)\n",
    "\n",
    "cat_cols = ['veh_body',\n",
    "            'area',\n",
    "            'gender',\n",
    "            'large_veh',\n",
    "            'expensive_area',\n",
    "            'expensive_age_risk',\n",
    "            'expensive_veh',\n",
    "            'severe_veh',\n",
    "            'young_dr',\n",
    "            'old_dr',\n",
    "            'new_veh',\n",
    "            'old_veh',\n",
    "            'frequent_area',\n",
    "            'young_dr_old_car',\n",
    "            'young_m_old_car',\n",
    "            'young_f_old_car',\n",
    "            'frequent_body',\n",
    "            'infrequent_body',\n",
    "            'young_m']\n",
    "\n",
    "rating_vars = ['young_dr_old_car',\n",
    "               'old_dr',\n",
    "               'young_dr',\n",
    "               'young_m_old_car',\n",
    "               'infrequent_body',\n",
    "               'frequent_body',\n",
    "               'young_f_old_car',\n",
    "               'new_veh', \n",
    "               'frequent_area',\n",
    "               'young_m']\n",
    "\n",
    "# Creating Categorical dataset for LightGBM and CatBoost\n",
    "df['lm_gender'] = np.where(df['gender'] == 'M', 1, 0)\n",
    "for i in cat_cols:\n",
    "    df[i] = df[i].astype('category')\n",
    "df['dr_age'] = df['dr_age'].astype(np.float64)\n",
    "df['veh_age'] = df['veh_age'].astype(np.float64) \n",
    "\n",
    "# Splitting into pred/response\n",
    "response_cols = ['fold',\n",
    "                 'exposure',\n",
    "                 'claim_ind',\n",
    "                 'claim_count',\n",
    "                 'claim_cost',\n",
    "                 'pure_premium',\n",
    "                 'severity',\n",
    "                 'frequency']\n",
    "X, y = df.drop(response_cols, axis=1), df[response_cols]\n",
    "X = X.drop('id', axis=1)\n",
    "X['exposure'] = y['exposure'].copy()\n",
    "lin_cols = ['veh_value', 'veh_body', 'veh_age', 'lm_gender', 'area', 'dr_age']\n",
    "boost_cols = ['veh_value', 'veh_body', 'veh_age', 'gender', 'area', 'dr_age']\n",
    "lin_sev_cols = lin_cols + ['exposure']\n",
    "boost_sev_cols = boost_cols + ['exposure']\n",
    "\n",
    "# Importing test set\n",
    "df_test = pd.read_csv('InsNova_test.csv')\n",
    "df_test['lm_gender'] = np.where(df_test['gender'] == 'M', 1, 0)\n",
    "df_test['large_veh'] = np.where(df_test['veh_body'].isin(['MIBUS', 'MCARA', 'BUS']), 1, 0)\n",
    "df_test['expensive_area'] = np.where(df_test['area'].isin(['E','F']), 1, 0)\n",
    "df_test['expensive_age_risk'] = np.where(df_test['dr_age'].isin([1, 2]) & (df_test['veh_value'] > 5.0), 1, 0)\n",
    "df_test['expensive_veh'] = np.where(df_test['veh_value'] > 6.0, 1, 0)\n",
    "df_test['severe_veh'] = np.where(df_test['veh_body'].isin(['HDTOP', 'TRUCK', 'UTE']), 1, 0)\n",
    "df_test['young_dr'] = np.where(df_test['dr_age'] == 1, 1, 0)\n",
    "df_test['old_dr'] = np.where(df_test['dr_age'] > 4.0, 1, 0)\n",
    "df_test['new_veh'] = np.where(df_test['veh_age'] < 2.0, 1, 0)\n",
    "df_test['old_veh'] = np.where(df_test['veh_age'] == 4.0, 1, 0)\n",
    "df_test['frequent_area'] = np.where(df_test['area'].isin(['B','F']), 1, 0)\n",
    "df_test['young_dr_old_car'] = np.where((df_test['dr_age'] == 1) & (df_test['veh_age'] > 1.0), 1, 0)\n",
    "df_test['young_m_old_car'] = np.where((df_test['dr_age'] == 1) & (df_test['veh_age'] > 1.0) & (df_test['gender'] == 'M'), 1, 0)\n",
    "df_test['young_f_old_car'] = np.where((df_test['dr_age'] == 1) & (df_test['veh_age'] > 1.0) & (df_test['gender'] == 'F'), 1, 0)\n",
    "df_test['frequent_body'] = np.where(df_test['veh_body'].isin(['BUS', 'COUPE', 'HDTOP', 'MCARA', 'PANVN', 'STNWG']), 1, 0)\n",
    "df_test['infrequent_body'] = np.where(df_test['veh_body'].isin(['MIBUS', 'UTE']), 1, 0)\n",
    "df_test['young_m'] = np.where((df_test['gender'] == 'M') & (df_test['dr_age'] < 3.0), 1, 0)\n",
    "\n",
    "for i in cat_cols:\n",
    "    df_test[i] = df_test[i].astype('category')\n",
    "    \n",
    "df_test['dr_age'] = df_test['dr_age'].astype(np.float64)\n",
    "df_test['veh_age'] = df_test['veh_age'].astype(np.float64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our gini function\n",
    "def gini(y_true, y_pred):\n",
    "    # check and get number of samples\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    n_samples = y_true.shape[0]\n",
    "    \n",
    "    # sort rows on prediction column \n",
    "    # (from largest to smallest)\n",
    "    arr = np.array([y_true, y_pred]).transpose()\n",
    "    true_order = arr[arr[:,0].argsort()][::-1,0]\n",
    "    pred_order = arr[arr[:,1].argsort()][::-1,0]\n",
    "    \n",
    "    # get Lorenz curves\n",
    "    L_true = np.cumsum(true_order) / np.sum(true_order)\n",
    "    L_pred = np.cumsum(pred_order) / np.sum(pred_order)\n",
    "    L_ones = np.linspace(1/n_samples, 1, n_samples)\n",
    "    \n",
    "    # get Gini coefficients (area between curves)\n",
    "    G_true = np.sum(L_ones - L_true)\n",
    "    G_pred = np.sum(L_ones - L_pred)\n",
    "    \n",
    "    # normalize to true Gini coefficient\n",
    "    return G_pred / G_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining column transformers for later steps          \n",
    "get_cats = make_column_selector(dtype_include=pd.CategoricalDtype)\n",
    "get_notcats = make_column_selector(dtype_exclude=pd.CategoricalDtype)\n",
    "get_notfloats = make_column_selector(dtype_exclude=np.float64)\n",
    "get_floats = make_column_selector(dtype_include=np.float64)\n",
    "get_ints = make_column_selector(dtype_include=[np.int32, np.int64])\n",
    "one_hot = lambda: ColumnTransformer([('one_hot', OneHotEncoder(drop='first', sparse=False), get_cats)], remainder='passthrough')\n",
    "\n",
    "# Initializing cross validated preds\n",
    "cv_freq_preds = {}\n",
    "test_freq_preds = {}\n",
    "cv_sev_preds = {}\n",
    "test_sev_preds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.190149963934325, -0.013077813242219507, 0.11724726635263655, -0.03613068840671824, 0.07796341189978917, 0.15483696518393744, 0.14191269695658587, -0.1169246443748487, 0.04851382484001185, 0.14148603232032858, 0.14076331839563852, 0.018533033523736413, -0.28679037859982986, -0.1930338204648662, 0.1153294150218813, 0.20055704805396818, 0.09827494790944377, -0.0014097935874787413, -0.03574337349051484, -0.0243584799022371]\n",
      "0.03690494661617848\n"
     ]
    }
   ],
   "source": [
    "# LGBM Classifier\n",
    "ind_lgbm = LGBMClassifier(n_estimators=750,\n",
    "                              learning_rate=0.1,\n",
    "                              num_leaves=31,\n",
    "                              subsample=0.8,\n",
    "                              subsample_freq=1,\n",
    "                              scale_pos_weight=(y.shape[0] - y['claim_ind'].sum()) / y['claim_ind'].sum(),\n",
    "                              n_jobs=-1)\n",
    "\n",
    "ginis = []\n",
    "for i in range(n_folds):\n",
    "    X_train, X_test, y_train, y_test = X.loc[y['fold'] != i, :], X.loc[y['fold'] == i, :], y.loc[y['fold'] != i, :], y.loc[y['fold'] == i, :]\n",
    "    ind_lgbm.fit(X_train[boost_sev_cols], y_train['claim_ind'])\n",
    "    ginis.append(gini(y_test['claim_cost'], ind_lgbm.predict_proba(X_test[boost_sev_cols])[:, 1]))\n",
    "print(ginis)\n",
    "print(np.mean(ginis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22629, 25)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
