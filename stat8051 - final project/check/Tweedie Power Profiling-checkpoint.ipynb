{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, cross_val_score, GroupKFold\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "from sklearn.metrics import make_scorer, mean_poisson_deviance, mean_gamma_deviance\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector, TransformedTargetRegressor\n",
    "from sklearn.preprocessing import PowerTransformer, OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegressionCV, RidgeCV, PoissonRegressor, GammaRegressor, TweedieRegressor\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "import statsmodels.api as sm\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all our data\n",
    "df = pd.read_csv('InsNova_train.csv')\n",
    "df = df.sample(frac=1.0)\n",
    "df.loc[:, 'pure_premium'] = df['claim_cost'] / df['exposure']\n",
    "df.loc[:, 'severity'] = df['claim_cost'] / np.fmax(df['claim_count'], 1)\n",
    "df.loc[:, 'frequency'] = df['claim_count'] / df['exposure']\n",
    "\n",
    "# Getting CV inds\n",
    "cv = StratifiedKFold(15, shuffle=True, random_state=123)\n",
    "df.loc[:, 'fold'] = 0\n",
    "for fold, (_, test_inds) in enumerate(cv.split(df, df['claim_ind'])):\n",
    "    df.loc[test_inds, 'fold'] = fold\n",
    "    \n",
    "# Prepping box-cox transformers\n",
    "box_cox = {}\n",
    "# Frequency\n",
    "df.loc[:,'bc_frequency'] = df['frequency'].copy()\n",
    "box_cox['frequency'] = PowerTransformer(method='box-cox', standardize=False)\n",
    "df.loc[df['frequency'] > 0.0, 'bc_frequency'] = box_cox['frequency'].fit_transform(df.loc[df['frequency'] > 0.0, 'frequency'].values.reshape(-1, 1)).flatten()\n",
    "# Severity\n",
    "df.loc[:,'bc_severity'] = df['severity'].copy()\n",
    "box_cox['severity'] = PowerTransformer(method='box-cox', standardize=False)\n",
    "df.loc[df['severity'] > 0.0, 'bc_severity'] = box_cox['severity'].fit_transform(df.loc[df['severity'] > 0.0, 'severity'].values.reshape(-1, 1)).flatten()\n",
    "# Pure premium\n",
    "df.loc[:,'bc_pure_premium'] = df['pure_premium'].copy()\n",
    "box_cox['pure_premium'] = PowerTransformer(method='box-cox', standardize=False)\n",
    "df.loc[df['pure_premium'] > 0.0, 'bc_pure_premium'] = box_cox['pure_premium'].fit_transform(df.loc[df['pure_premium'] > 0.0, 'pure_premium'].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Splitting into pred/response\n",
    "sev_mask = df['claim_ind'] == 1\n",
    "response_cols = ['fold',\n",
    "                 'exposure',\n",
    "                 'claim_ind',\n",
    "                 'claim_count',\n",
    "                 'claim_cost',\n",
    "                 'pure_premium',\n",
    "                 'severity',\n",
    "                 'frequency',\n",
    "                 'bc_pure_premium',\n",
    "                 'bc_severity',\n",
    "                 'bc_frequency']\n",
    "X, y = df.drop(response_cols, axis=1), df[response_cols]\n",
    "X = X.drop('id', axis=1)\n",
    "\n",
    "# Adding a condensed veh_body column\n",
    "other_bodies = ['TRUCK', 'COUPE', 'MIBUS', 'PANVN', 'BUS', 'RDSTR', 'MCARA', 'CONVT']\n",
    "X.loc[:,'veh_body2'] = np.where(X['veh_body'].isin(other_bodies), 'OTHER', X['veh_body'])\n",
    "X.loc[:,'log_veh_value'] = np.log(X['veh_value'] + 0.1)\n",
    "\n",
    "# Creating Categorical dataset for LightGBM and CatBoost\n",
    "for i in ['veh_body', 'veh_body2', 'gender', 'area']:\n",
    "    X[i] = X[i].astype('category')\n",
    "X_sev = X[y['claim_cost'] > 0.0]\n",
    "y_sev = y[y['claim_cost'] > 0.0]\n",
    "lin_cols = ['veh_body', 'veh_age', 'gender', 'area', 'dr_age', 'log_veh_value']\n",
    "boost_cols = ['veh_value', 'veh_body', 'veh_age', 'gender', 'area', 'dr_age']\n",
    "    \n",
    "# Defining column transformers for later steps          \n",
    "get_cats = make_column_selector(dtype_include=pd.CategoricalDtype)\n",
    "one_hot = lambda: ColumnTransformer([('one_hot', OneHotEncoder(drop='first', sparse=False), get_cats)], remainder='passthrough')\n",
    "\n",
    "# Initializing cross validated preds\n",
    "cv_preds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_pipeline(ColumnTransformer([('one_hot', OneHotEncoder(drop='first', sparse=False), get_cats)], remainder='passthrough'),\n",
    "                             StandardScaler())\n",
    "_X = preprocessor.fit_transform(X[lin_cols])\n",
    "_X = sm.add_constant(_X, prepend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.GLM(y['pure_premium'], _X, family=sm.families.Tweedie(var_power=1.2), freq_weights=y['exposure'])\n",
    "results = model.fit_regularized(maxiter=200, L1_wt=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.predict(_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1       0.0\n",
       "x2       0.0\n",
       "x3       0.0\n",
       "x4       0.0\n",
       "x5       0.0\n",
       "x6       0.0\n",
       "x7       0.0\n",
       "x8       0.0\n",
       "x9       0.0\n",
       "x10      0.0\n",
       "x11      0.0\n",
       "x12      0.0\n",
       "x13      0.0\n",
       "x14      0.0\n",
       "x15      0.0\n",
       "x16      0.0\n",
       "x17      0.0\n",
       "x18      0.0\n",
       "x19      0.0\n",
       "x20      0.0\n",
       "x21      0.0\n",
       "const    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.102456591998465"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.model.estimate_tweedie_power(results.fittedvalues, low=1.01, high=2.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
